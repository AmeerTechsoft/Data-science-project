{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmeerTechsoft/Data-science-project/blob/main/IoT_Weather_Predictor_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IoT Temperature and Humidity Predictor using AutoTS Algorithm**\n",
        "AutoTS is an automated time series forecasting library in Python that uses a genetic algorithm to search for the best model parameters for a given dataset. It is built on top of the popular machine learning library scikit-learn and provides a simple, easy-to-use interface for training and evaluating time series models.\n",
        "\n",
        "AutoTS can handle various time series forecasting tasks, including univariate, multivariate, and forecasting with missing values. It also provides a range of models, including classical statistical models such as ARIMA and exponential smoothing, as well as machine learning models such as Random Forests and XGBoost.\n",
        "\n",
        "One of the key benefits of AutoTS is its ability to automatically select the best model parameters without requiring manual tuning. This is accomplished by using a genetic algorithm to search for the best model parameters based on a given set of evaluation metrics. This makes it particularly useful for data scientists and analysts who may not have deep expertise in time series modeling but still need to generate accurate forecasts.\n",
        "\n",
        "Overall, AutoTS is a powerful and flexible tool for time series forecasting that can help users save time and effort in selecting and training models."
      ],
      "metadata": {
        "id": "VQX_3WIIy1OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing AutoTS\n",
        "!pip install autots"
      ],
      "metadata": {
        "id": "mQz985Nro4T7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Declearing Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from autots import AutoTS\n",
        "from autots.datasets import load_daily"
      ],
      "metadata": {
        "id": "b4-rkzd-zYKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CHANNEL_ID = 2039086\n",
        "\n",
        "# Load data from ThingSpeak channel as .CSV into dataframe\n",
        "data = pd.read_csv(f'https://api.thingspeak.com/channels/{CHANNEL_ID}/feeds.csv?&results=10000')\n",
        "\n",
        "# Shows what the dataframe contains\n",
        "data.info()"
      ],
      "metadata": {
        "id": "Ce-mLKaUzngo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data\n"
      ],
      "metadata": {
        "id": "cBO2ljmzwBOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #converting Field1 and Field2 to Float string type\n",
        "\n",
        " data['field1'] = pd.to_numeric(data['field1'], errors='coerce').astype(float)\n",
        "\n",
        " data['field2'] = pd.to_numeric(data['field2'], errors='coerce').astype(float)"
      ],
      "metadata": {
        "id": "AdVxyyy5jsYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for empty fields\n",
        "\n",
        "data.isna().sum()"
      ],
      "metadata": {
        "id": "r87iDTiJXlWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Droping Empty fields\n",
        "data.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "wKRhn6PweVde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for empty fields\n",
        "data.isna().sum()"
      ],
      "metadata": {
        "id": "XeRkeuBReqEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytz\n",
        "\n",
        "timezone_wca = pytz.timezone('Africa/Lagos')\n",
        "\n",
        "\n",
        "# Convert timestamp to datetime format\n",
        "data['created_at'] = pd.to_datetime(data['created_at']).dt.tz_convert(timezone_wca)\n",
        "\n",
        "# Set timestamp as index\n",
        "data.set_index('created_at', inplace=True)\n"
      ],
      "metadata": {
        "id": "WSJ5bt8MzydB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "tsP_jTJ2gRvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertingthe data to hourly to make it regular\n",
        "\n",
        "data_hourly = data.resample(\"H\").mean().fillna(method=\"ffill\")"
      ],
      "metadata": {
        "id": "95zq9GRFgxc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select temperature data and humidity data from dataframe\n",
        "temp_data = data_hourly['field1']\n",
        "hum_data = data_hourly['field2']"
      ],
      "metadata": {
        "id": "yQIch9qIz421"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_hourly.info()"
      ],
      "metadata": {
        "id": "9UyG9yq7fozJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The **AutoTS** object is an instance of the Auto Time Series forecasting library, which is a Python library used for time series forecasting. It is designed to automatically search for the best forecasting model for a given time series dataset by trying different combinations of models and parameters, and evaluating them using various metrics.\n",
        "\n",
        "\n",
        "\n",
        "### In this specific code, the ** _model object is created using AutoTS with the following parameters:\n",
        "\n",
        "*   **forecast_length**: the number of time steps to forecast, which is set to 6 to forecast every 4 hours for a day.\n",
        "*   **frequency**: the frequency of the time series, which is set to 4 hours.\n",
        "* **prediction_interval**: the prediction interval, which is set to 0.7 to generate a 70% prediction interval for the forecasts.\n",
        "* **ensemble**: the type of ensemble method to use, which is set to 'simple'\n",
        "* **model_list**: the list of models to use, which is set to 'multivariate' to use models that can handle multiple input variables.\n",
        "* **ransformer_list**: the list of transformers to use, which is set to 'superfast' for faster computation.\n",
        "* **drop_most_recent**: the number of most recent time steps to drop from the input data, which is set to 1.\n",
        "* **max_generations**: the maximum number of generations for the genetic algorithm used to search for the best models and parameters, which is set to 5.\n",
        "* **num_validations**: the number of cross-validation folds to use, which is set to 1.\n",
        "* **models_to_validate**: the proportion of models to validate during the search, which is set to 0.2.\n",
        "* **n_jobs**: the number of CPU cores to use for parallel computation, which is set to 100.\n"
      ],
      "metadata": {
        "id": "6BEzzdin0nwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping the Unsued column \"entry_id\"\n",
        "data_hourly = data_hourly.drop(['entry_id'], axis=1)"
      ],
      "metadata": {
        "id": "Mx1gk6Yhx-ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "from keras.callbacks import EarlyStopping\n",
        "import requests\n",
        "from autots import AutoTS\n",
        "import pickle\n",
        "\n",
        "\n",
        "# Split data into training and testing sets\n",
        "train_size = int(len(data_hourly) * 0.7)\n",
        "train = data_hourly[:train_size]\n",
        "test = data_hourly[train_size:]"
      ],
      "metadata": {
        "id": "G8sJg5HwxYMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['field1'].plot(figsize=(12,5))\n",
        "test['field1'].plot(figsize=(12, 5))\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "E1n6dvbfYG7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_temp = pd.DataFrame(train['field1'])\n",
        "train_temp"
      ],
      "metadata": {
        "id": "AFT5ebcMYsGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model for temp\n",
        "model = AutoTS(\n",
        "    forecast_length=12,  # Forecasting every 4 hours for a day, so 6 forecasts\n",
        "    frequency='2H',\n",
        "    prediction_interval=0.9,\n",
        "    ensemble='simple',\n",
        "    model_list='multivariate',\n",
        "    transformer_list='superfast',\n",
        "    drop_most_recent=1,\n",
        "    max_generations=5,\n",
        "    num_validations=1,\n",
        "    models_to_validate=0.2,\n",
        "    n_jobs=100,\n",
        ")"
      ],
      "metadata": {
        "id": "IZ2md_5UZIN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train)"
      ],
      "metadata": {
        "id": "F8ryWX_2ZQCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(test)"
      ],
      "metadata": {
        "id": "Ax9ecPKdcPZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vL0k3h2ecNvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (train.info)\n",
        "print (test.info)"
      ],
      "metadata": {
        "id": "EFZpqqOiy3aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model for temp\n",
        "temp_model = AutoTS(\n",
        "    forecast_length=6,  # Forecasting every 4 hours for a day, so 6 forecasts\n",
        "    frequency='4H',\n",
        "    prediction_interval=0.9,\n",
        "    ensemble='simple',\n",
        "    model_list='multivariate',\n",
        "    transformer_list='superfast',\n",
        "    drop_most_recent=1,\n",
        "    max_generations=5,\n",
        "    num_validations=1,\n",
        "    models_to_validate=0.2,\n",
        "    n_jobs=100,\n",
        ")\n",
        "\n",
        "\n",
        "# model for humidity\n",
        "hum_model = AutoTS(\n",
        "    forecast_length=6,  # Forecasting every 4 hours for a day, so 6 forecasts\n",
        "    frequency='4H',\n",
        "    prediction_interval=0.9,\n",
        "    ensemble='simple',\n",
        "    model_list='multivariate',\n",
        "    transformer_list='superfast',\n",
        "    drop_most_recent=1,\n",
        "    max_generations=5,\n",
        "    num_validations=1,\n",
        "    models_to_validate=0.2,\n",
        "    n_jobs=100,\n",
        ")\n"
      ],
      "metadata": {
        "id": "6qJGgzJo0CsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Temprature forecast**\n",
        "\n",
        "###**temp_model.fit(temp_data)**\n",
        "is a method call to fit the **temp_data** into the **temp_model** instance using the AutoTS algorithm. This method trains the model and finds the best-fitted model based on the given input data and parameters.\n",
        "\n",
        "###**temp_forecast = temp_model.predict()**\n",
        "forecast is a method call to make a forecast using the **temp_model** instance. This method uses the trained model to make future predictions and returns the forecasted values for the specified **forecast_length**. In this case, the forecast length is set to 6, which means the method returns 6 forecasted values for temperature at an interval of every 4 hours."
      ],
      "metadata": {
        "id": "SV1Vf2Vg4ZRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_modelling = temp_model.fit(df_scaled)\n",
        "# temp_forecast = temp_model.predict().forecast"
      ],
      "metadata": {
        "id": "xOGPDfhO5A2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_modelling"
      ],
      "metadata": {
        "id": "BpaPorQr1W2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "oCTphlZ0-w0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autots.evaluation import TSUtil\n",
        "metrics = TSUtil.metrics(test, temp_forecast)\n",
        "print(metrics)"
      ],
      "metadata": {
        "id": "MG0cHqOwJ_iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_forecast = temp_modelling.predict(data_hourly['field1']).forecast"
      ],
      "metadata": {
        "id": "MJdWA8i943gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_forecast"
      ],
      "metadata": {
        "id": "1W5T2CyW5B4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CdakopoUFwI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Humidity forecast**\n",
        "###**hum_model.fit(hum_data)**\n",
        "is a method call to fit the **hum_data** into the **hum_model** instance using the AutoTS algorithm. This method trains the model and finds the best-fitted model based on the given input data and parameters.\n",
        "\n",
        "###**hum_forecast = hum_model.predict()**\n",
        "forecast is a method call to make a forecast using the **hum_model** instance. This method uses the trained model to make future predictions and returns the forecasted values for the specified **forecast_length**. In this case, the forecast length is set to 6, which means the method returns 6 forecasted values for temperature at an interval of every 4 hours."
      ],
      "metadata": {
        "id": "ZHy39Y-O5IKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hum_model.fit(hum_data)\n",
        "hum_forecast = hum_model.predict().forecast\n"
      ],
      "metadata": {
        "id": "nQXDgVT24X2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Ploting the Forcasted Temprature and Humidity**"
      ],
      "metadata": {
        "id": "NUZkMd9V6z4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot actual and forecasted temperature and humidity\n",
        "fig, ax = plt.subplots(figsize=(50, 15))\n",
        "ax.plot(temp_data.index, temp_data, label='Temperature Actual')\n",
        "ax.plot(temp_forecast.index, temp_forecast, label='Temperature Forecast')\n",
        "ax.plot(hum_data.index, hum_data, label='Humidity Actual')\n",
        "ax.plot(hum_forecast.index, hum_forecast, label='Humidity Forecast')"
      ],
      "metadata": {
        "id": "fLP19XC_6zPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Plot upper and lower forecast bounds as shaded region**"
      ],
      "metadata": {
        "id": "i71q82V17jxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot upper and lower forecast bounds as shaded region\n",
        "fig, ax = plt.subplots(figsize=(20, 6))\n",
        "temp_up, temp_low = temp_model.predict().upper_forecast.squeeze(), temp_model.predict().lower_forecast.squeeze()\n",
        "hum_up, hum_low = hum_model.predict().upper_forecast.squeeze(), hum_model.predict().lower_forecast.squeeze()\n",
        "ax.fill_between(temp_up.index, temp_up.values, temp_low.values, alpha=0.6)\n",
        "ax.fill_between(hum_up.index, hum_up.values, hum_low.values, alpha=0.6)\n",
        "\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X11n36g07Bnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**The Date and Time format is**\n",
        "\n",
        "###**03-24 20**\n",
        "###**MM-DD HH**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "###**03**: MONTH\n",
        "###**24**: DAY\n",
        "###**20**: HOUR\n",
        "\n"
      ],
      "metadata": {
        "id": "zbQkwVgo_bVq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#STOP"
      ],
      "metadata": {
        "id": "lXBvdqEf6KSv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TEST"
      ],
      "metadata": {
        "id": "F5h03PWd9gC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hum_forecast"
      ],
      "metadata": {
        "id": "Kq68Gu14HJOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# assume your model is named 'model'\n",
        "with open('temp_model.pkl', 'wb') as file:\n",
        "    pickle.dump(temp_model, file)\n",
        "\n",
        "with open('hum_model.pkl', 'wb') as file:\n",
        "    pickle.dump(hum_model, file)"
      ],
      "metadata": {
        "id": "wEIv3VxGIQnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hum_model"
      ],
      "metadata": {
        "id": "6V1eCaDc7hGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the predictions into a single DataFrame\n",
        "preds = pd.merge(temp_forecast, hum_forecast, left_index=True, right_index=True)\n",
        "\n",
        "\n",
        "# Export the predictions to a CSV file\n",
        "preds.to_csv('predicted/predictions.csv')"
      ],
      "metadata": {
        "id": "504lutDvDb_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_forecast = temp_forecast.rename(columns={\"field1\": \"field3\"})\n",
        "hum_forecast = hum_forecast.rename(columns={\"field2\": \"field4\"})"
      ],
      "metadata": {
        "id": "s-t4nGkUURAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hum_forecast.info()"
      ],
      "metadata": {
        "id": "2HSa6j1DcBHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Set ThingSpeak parameters\n",
        "api_key = '2QE7XJFM47BKNNE6'\n",
        "url = 'https://api.thingspeak.com/update'\n",
        "\n",
        "# Get the predicted values\n",
        "# temp_forecast = temp_model.predict().forecast\n",
        "# hum_forecast = hum_model.predict().forecast\n",
        "\n",
        "\n",
        "# Construct the payload\n",
        "payload = {'api_key': api_key,\n",
        "           'field3': temp_forecast,  # Send only the last forecasted value\n",
        "           'field4': hum_forecast}   # Send only the last forecasted value\n",
        "\n",
        "# Send the data to ThingSpeak\n",
        "response = requests.post(url, data=payload)\n",
        "\n",
        "# Print the response\n",
        "print(response.content)\n",
        "\n",
        "print (temp_forecast)\n",
        "print (hum_forecast)\n",
        "\n"
      ],
      "metadata": {
        "id": "b9R7yUoD_aKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 6))\n",
        "plt.plot(temp_data.index, temp_data, label='Actual temperature')\n",
        "plt.plot(temp_forecast.index, temp_forecast, label='Predicted temperature')\n",
        "plt.legend()\n",
        "plt.title('Temperature forecast using AutoARIMA')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Temperature')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HJsJsZ_1gYwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip freeze\n"
      ],
      "metadata": {
        "id": "M6-adIKdK2D2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Declearing Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from autots import AutoTS\n",
        "from autots.datasets import load_daily\n",
        "import pytz\n",
        "\n",
        "\n",
        "CHANNEL_ID = 2039086\n",
        "\n",
        "# Load data from ThingSpeak channel as .CSV into dataframe\n",
        "data = pd.read_csv(f'https://api.thingspeak.com/channels/{CHANNEL_ID}/feeds.csv?&results=500')\n",
        "\n",
        "# Shows what the dataframe contains\n",
        "\n",
        "# converting Field1 and Field2 to Float string type\n",
        "\n",
        "data['field1'] = pd.to_numeric(data['field1'], errors='coerce').astype(float)\n",
        "\n",
        "data['field2'] = pd.to_numeric(data['field2'], errors='coerce').astype(float)\n",
        "\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "timezone_wca = pytz.timezone('Africa/Lagos')\n",
        "\n",
        "\n",
        "# Convert timestamp to datetime format\n",
        "data['created_at'] = pd.to_datetime(data['created_at']).dt.tz_convert(timezone_wca)\n",
        "\n",
        "# Set timestamp as index\n",
        "data.set_index('created_at', inplace=True)\n",
        "data_hourly = data.resample(\"H\").mean().fillna(method=\"ffill\")\n",
        "\n",
        "# Select temperature data and humidity data from dataframe\n",
        "temp_data = data_hourly['field1']\n",
        "hum_data = data_hourly['field2']\n",
        "\n",
        "# model for temp\n",
        "temp_model = AutoTS(\n",
        "    forecast_length=6,  # Forecasting every 4 hours for a day, so 6 forecasts\n",
        "    frequency='4H',\n",
        "    prediction_interval=0.7,\n",
        "    ensemble='simple',\n",
        "    model_list='multivariate',\n",
        "    transformer_list='superfast',\n",
        "    drop_most_recent=1,\n",
        "    max_generations=5,\n",
        "    num_validations=1,\n",
        "    models_to_validate=0.2,\n",
        "    n_jobs=100,\n",
        ")\n",
        "\n",
        "\n",
        "# model for humidity\n",
        "hum_model = AutoTS(\n",
        "    forecast_length=6,  # Forecasting every 4 hours for a day, so 6 forecasts\n",
        "    frequency='4H',\n",
        "    prediction_interval=0.7,\n",
        "    ensemble='simple',\n",
        "    model_list='multivariate',\n",
        "    transformer_list='superfast',\n",
        "    drop_most_recent=1,\n",
        "    max_generations=5,\n",
        "    num_validations=1,\n",
        "    models_to_validate=0.2,\n",
        "    n_jobs=100,\n",
        "\n",
        ")\n",
        "\n",
        "temp_model.fit(temp_data)\n",
        "temp_forecast = temp_model.predict().forecast\n",
        "\n",
        "hum_model.fit(hum_data)\n",
        "hum_forecast = hum_model.predict().forecast\n",
        "\n",
        "# Combine the predictions into a single DataFrame\n",
        "preds = pd.merge(temp_forecast, hum_forecast, left_index=True, right_index=True)\n",
        "\n",
        "\n",
        "# Export the predictions to a CSV file\n",
        "preds.to_csv('predicted/predictions.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "EmipaHKwZKmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Export the predictions to a CSV file\n",
        "preds.to_csv('predicted/predictions.csv')"
      ],
      "metadata": {
        "id": "I4K1fJzZaQ4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "from keras.callbacks import EarlyStopping\n",
        "import requests\n",
        "from autots import AutoTS\n",
        "import pickle\n",
        "\n",
        "# Set up ThingSpeak API key and channel ID\n",
        "api_key = 'LXOTOE6HKVWNHZ63'\n",
        "channel_id = '2039086'\n",
        "\n",
        "# Get data from ThingSpeak\n",
        "url = 'https://api.thingspeak.com/channels/{}/feeds.json?api_key={}&results=1000'.format(channel_id, api_key)\n",
        "response = requests.get(url)\n",
        "data = response.json()['feeds']\n",
        "df = pd.DataFrame(data)\n",
        "df['created_at'] = pd.to_datetime(df['created_at'])\n",
        "df.set_index('created_at', inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "df['field1'] = pd.to_numeric(df['field1'], errors='coerce').astype(float)\n",
        "\n",
        "df['field2'] = pd.to_numeric(df['field2'], errors='coerce').astype(float)\n",
        "df = df[['field1', 'field2']]\n",
        "df.columns = ['temperature', 'humidity']\n",
        "df = df.resample(\"4H\").mean().fillna(method=\"ffill\")\n",
        "\n",
        "# Normalize data\n",
        "scaler = MinMaxScaler()\n",
        "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns, index=df.index)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "train_size = int(len(df_scaled) * 0.7)\n",
        "train = df_scaled[:train_size]\n",
        "test = df_scaled[train_size:]\n",
        "\n",
        "# Set up AutoTS\n",
        "# model = AutoTS(\n",
        "#     forecast_length=6,\n",
        "#     frequency='4H',\n",
        "#     ensemble='stacked',\n",
        "#     max_generations=10,\n",
        "#     validation_method='backwards',\n",
        "#     verbose=2\n",
        "# )\n",
        "model = AutoTS(\n",
        "    forecast_length=6,\n",
        "    frequency='4H',\n",
        "    ensemble='all',\n",
        "    max_generations=6,\n",
        "    validation_method='Seasonal 364',\n",
        "    verbose=2,\n",
        "    min_allowed_train_percent=0.8,\n",
        "    prediction_interval=0.9\n",
        ")\n",
        "# Train model on training data\n",
        "model = model.fit(train)\n",
        "\n",
        "# Make predictions on testing data\n",
        "# predictions = model.predict(test)\n",
        "# predictions = pd.DataFrame(predictions, columns=test.columns, index=test.index)\n",
        "\n",
        "# # Plot actual values and predicted values\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# sns.lineplot(data=test, dashes=False)\n",
        "# sns.lineplot(data=predictions, dashes=True)\n",
        "# plt.legend(['Actual Temperature', 'Actual Humidity', 'Predicted Temperature', 'Predicted Humidity'])\n",
        "# plt.xlabel('Date')\n",
        "# plt.ylabel('Normalized Value')\n",
        "# plt.title('Actual vs. Predicted Temperature and Humidity')\n",
        "# plt.show()\n",
        "\n",
        "# # Save model\n",
        "# filename = 'autots_model.sav'\n",
        "# pickle.dump(model, open(filename, 'wb'))\n",
        "\n",
        "# # Load model\n",
        "# loaded_model = pickle.load(open(filename, 'rb'))\n",
        "\n",
        "# # Use loaded model to make predictions\n",
        "# new_predictions = loaded_model.predict(test)\n"
      ],
      "metadata": {
        "id": "SiqE5GnSrKwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.index = pd.to_datetime(test.index)"
      ],
      "metadata": {
        "id": "xGuwkEJnRBQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pandas scikit-learn\n"
      ],
      "metadata": {
        "id": "UbPz5SwiSBvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "X2ds_vWBVvle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# assume your model is named 'model'\n",
        "with open('model.pkl', 'wb') as file:\n",
        "    pickle.dump(model, file)\n"
      ],
      "metadata": {
        "id": "HE3PziYrXVMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on testing data\n",
        "predictions = model.predict(forecast_length=6).forecast\n",
        "predictions = pd.DataFrame(predictions, columns=test.columns, index=test.index)\n",
        "\n",
        "# Plot actual values and predicted values\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(data=test, dashes=False)\n",
        "sns.lineplot(data=predictions, dashes=True)\n",
        "plt.legend(['Actual Temperature', 'Actual Humidity', 'Predicted Temperature', 'Predicted Humidity'])\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Normalized Value')\n",
        "plt.title('Actual vs. Predicted Temperature and Humidity')\n",
        "plt.show()\n",
        "\n",
        "# # Save model\n",
        "# filename = 'autots_model.sav'\n",
        "# pickle.dump(model, open(filename, 'wb'))\n",
        "\n",
        "# # Load model\n",
        "# loaded_model = pickle.load(open(filename, 'rb'))\n",
        "\n",
        "# # Use loaded model to make predictions\n",
        "# new_predictions = loaded_model.predict(test)"
      ],
      "metadata": {
        "id": "LoNj1ewuQmB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "DMEhVYC-anQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from autots import AutoTS\n",
        "\n",
        "# Load data from Thingspeak channel\n",
        "api_key = 'LXOTOE6HKVWNHZ63'\n",
        "channel_id = '2039086'\n",
        "\n",
        "\n",
        "df = pd.read_csv(f'https://api.thingspeak.com/channels/{channel_id}/feeds.csv?api_key={api_key}&results=1000')\n",
        "\n",
        "# Convert timestamp to datetime format\n",
        "df['created_at'] = pd.to_datetime(df['created_at'])\n",
        "df['field1'] = pd.to_numeric(df['field1'], errors='coerce').astype(float)\n",
        "\n",
        "df['field2'] = pd.to_numeric(df['field2'], errors='coerce').astype(float)\n",
        "\n",
        "# Set timestamp as index\n",
        "df = df.set_index('created_at')\n",
        "\n",
        "# Split data into training and testing sets\n",
        "forecast_length = 6\n",
        "min_allowed_train_percent = 0.9\n",
        "train_length = int(len(df) * min_allowed_train_percent)\n",
        "train = df.iloc[:train_length]\n",
        "test = df.iloc[train_length:train_length+forecast_length]\n",
        "\n",
        "\n",
        "# Instantiate AutoTS model\n",
        "model = AutoTS(\n",
        "    forecast_length=forecast_length,\n",
        "    frequency='H',\n",
        "    prediction_interval=0.9,\n",
        "    ensemble='all',\n",
        "    max_generations=3,\n",
        "    num_validations=1,\n",
        "    validation_method='backwards',\n",
        "    model_list=['ARIMA', 'Prophet', 'VAR', 'Theta',]\n",
        ")\n",
        "\n",
        "# Train model on training data\n",
        "model = model.fit(train)\n",
        "\n",
        "# Make predictions on testing data\n",
        "predictions = model.predict(test)\n",
        "predictions = pd.DataFrame(predictions, columns=test.columns, index=test.index)\n",
        "\n",
        "# Save model\n",
        "model.save('model.pkl')\n"
      ],
      "metadata": {
        "id": "DhRXY-N3DTMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from datetime import datetime, timedelta\n",
        "import pytz\n",
        "\n",
        "# Load temperature and humidity models\n",
        "with open('temp_model.pkl', 'rb') as f:\n",
        "    temp_model = pickle.load(f)\n",
        "\n",
        "with open('hum_model.pkl', 'rb') as f:\n",
        "    hum_model = pickle.load(f)\n",
        "\n",
        "# Collect data from ThingSpeak API\n",
        "CHANNEL_ID = 2039086\n",
        "\n",
        "# Load data from ThingSpeak channel as .CSV into dataframe\n",
        "data = pd.read_csv(f'https://api.thingspeak.com/channels/{CHANNEL_ID}/feeds.csv?&results=500')\n",
        "\n",
        "data['field1'] = pd.to_numeric(data['field1'], errors='coerce').astype(float)\n",
        "\n",
        "data['field2'] = pd.to_numeric(data['field2'], errors='coerce').astype(float)\n",
        "data.dropna(inplace=True)\n",
        "timezone_wca = pytz.timezone('Africa/Lagos')\n",
        "\n",
        "\n",
        "# Convert timestamp to datetime format\n",
        "data['created_at'] = pd.to_datetime(data['created_at']).dt.tz_convert(timezone_wca)\n",
        "\n",
        "# Set timestamp as index\n",
        "data.set_index('created_at', inplace=True)\n",
        "\n",
        "\n",
        "data_hourly = data.resample(\"H\").mean().fillna(method=\"ffill\")\n",
        "\n",
        "temp = data['field1']\n",
        "hum = data['field2']\n",
        "\n",
        "# Generate timestamp for current day at 00:00\n",
        "now = datetime.now()\n",
        "today = datetime(now.year, now.month, now.day)\n",
        "timestamps = [today + timedelta(hours=i) for i in range(0, 24, 4)]\n",
        "\n",
        "# Create DataFrame with features for temperature and humidity models\n",
        "# temp_features = pd.DataFrame({'hour': [ts.hour for ts in timestamps],\n",
        "#                               'month': [ts.month for ts in timestamps],\n",
        "#                               'weekday': [ts.weekday() for ts in timestamps],\n",
        "#                               'temp_1': temp,\n",
        "#                               'hum_1': hum})\n",
        "# hum_features = pd.DataFrame({'hour': [ts.hour for ts in timestamps],\n",
        "#                              'month': [ts.month for ts in timestamps],\n",
        "#                              'weekday': [ts.weekday() for ts in timestamps],\n",
        "#                              'temp_1': temp,\n",
        "#                              'hum_1': hum})\n",
        "\n",
        "# Make predictions using the models\n",
        "# temp_preds = temp_model.predict(temp).forecast\n",
        "# hum_preds = hum_model.predict(hum).forecast\n",
        "\n",
        "import pandas as pd\n",
        "import autots\n",
        "from autots import AutoTS\n",
        "\n",
        "# Load the saved model\n",
        "temp_model = autots.load('temp_model.pkl')\n",
        "hum_model = autots.load('hum_model.pkl')\n",
        "\n",
        "# Prepare the data\n",
        "data = pd.read_csv(f'https://api.thingspeak.com/channels/{CHANNEL_ID}/feeds.csv?&results=500')\n",
        "\n",
        "data['field1'] = pd.to_numeric(data['field1'], errors='coerce').astype(float)\n",
        "\n",
        "data['field2'] = pd.to_numeric(data['field2'], errors='coerce').astype(float)\n",
        "data.dropna(inplace=True)\n",
        "timezone_wca = pytz.timezone('Africa/Lagos')\n",
        "\n",
        "\n",
        "# Convert timestamp to datetime format\n",
        "data['created_at'] = pd.to_datetime(data['created_at']).dt.tz_convert(timezone_wca)\n",
        "\n",
        "# Set timestamp as index\n",
        "data.set_index('created_at', inplace=True)\n",
        "\n",
        "\n",
        "data_hourly = data.resample(\"H\").mean().fillna(method=\"ffill\")\n",
        "\n",
        "temp = data['field1']\n",
        "hum = data['field2']\n",
        "\n",
        "# Make forecasts\n",
        "# forecasts = model.predict(data)\n",
        "temp_preds = temp_model.predict(temp).forecast\n",
        "hum_preds = hum_model.predict(hum).forecast\n",
        "\n",
        "# Evaluate the results\n",
        "# actuals = data['target_variable']\n",
        "# mae = mean_absolute_error(actuals, temp_preds)\n",
        "# mse = mean_squared_error(actuals, temp_preds)\n",
        "# mae = mean_absolute_error(actuals, hum_preds)\n",
        "# mse = mean_squared_error(actuals, hum_preds)\n",
        "# # rmse = np.sqrt(mse)\n",
        "# # r2 = r2_score(actuals, forecasts)\n"
      ],
      "metadata": {
        "id": "vXnlkhbV-uwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_preds"
      ],
      "metadata": {
        "id": "XqLSQcOeC1ai"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}